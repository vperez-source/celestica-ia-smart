import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from bs4 import BeautifulSoup
from scipy.stats import gaussian_kde

# --- CONFIGURACI√ìN ---
st.set_page_config(page_title="Celestica AI Self-Explainer", layout="wide", page_icon="üïµÔ∏è")
st.title("üïµÔ∏è Celestica IA: Smart-Tracker & Diagnostic Engine")

with st.sidebar:
    st.header("‚öôÔ∏è Baseline de Ingenier√≠a")
    tc_esperado_seg = st.number_input("TC Objetivo Esperado (seg)", value=110)
    h_turno = st.number_input("Horas Turno", value=8.0)
    st.divider()
    st.info("Si el resultado se desv√≠a del objetivo, la IA generar√° una explicaci√≥n t√©cnica.")

# --- 1. LECTOR DE ALTA PRECISI√ìN ---
def parse_xml_tanque(file):
    try:
        content = file.getvalue().decode('latin-1', errors='ignore')
        soup = BeautifulSoup(content, 'lxml-xml')
        data = [[c.get_text(strip=True) for c in row.find_all(['Cell', 'ss:Cell'])] 
                for row in soup.find_all(['Row', 'ss:Row'])]
        return pd.DataFrame([d for d in data if d])
    except: return None

@st.cache_data(ttl=3600)
def load_and_map(file):
    df = parse_xml_tanque(file)
    if df is None or df.empty:
        try:
            file.seek(0)
            df = pd.read_excel(file, header=None)
        except: return None, None
    
    df = df.astype(str)
    # Buscador de cabeceras avanzado
    for i in range(min(100, len(df))):
        row = " ".join(df.iloc[i]).lower()
        if any(x in row for x in ['date', 'time', 'station', 'productid', 'sn']):
            df.columns = df.iloc[i].str.strip()
            return df[i+1:].reset_index(drop=True), i
    return None, None

# --- 2. MOTOR DE C√ÅLCULO Y EXPLICACI√ìN ---
def analyze_with_explanation(df, tc_obj_seg):
    c_fec = next((c for c in df.columns if any(x in c.lower() for x in ['date', 'time', 'fecha'])), None)
    c_sn = next((c for c in df.columns if any(x in c.lower() for x in ['serial', 'sn', 'unitid'])), None)
    
    # Limpieza
    df[c_fec] = pd.to_datetime(df[c_fec], errors='coerce', dayfirst=True)
    df = df.dropna(subset=[c_fec]).sort_values(c_fec)
    if c_sn: df = df.drop_duplicates(subset=[c_sn], keep='first')
    
    # Imputaci√≥n de r√°fagas
    batches = df.groupby(c_fec).size().reset_index(name='piezas')
    batches['gap'] = batches[c_fec].diff().dt.total_seconds().fillna(0)
    batches['tc_unitario'] = batches['gap'] / batches['piezas']
    
    # --- CAMBIO EN EL FILTRO DE FLUJO ---
# Bajamos el suelo a 1s y subimos el techo a 30min para encontrar CUALQUIER rastro de vida
frontera_data = batches[(batches['tc_unitario'] >= 1) & (batches['tc_unitario'] <= 1800)]['tc_unitario']

if len(frontera_data) < 2: # Bajamos el m√≠nimo de muestras de 5 a 2
    # Si sigue fallando, es que el archivo est√° colapsado. 
    # Usamos el TIEMPO TOTAL dividido por PIEZAS TOTALES como √∫ltimo recurso.
    duracion_total = (df[c_fec].max() - df[c_fec].min()).total_seconds()
    tc_emergencia = duracion_total / len(df)
    return {
        'teorico': tc_emergencia / 60,
        'real': tc_emergencia / 60,
        'modo_seg': tc_emergencia,
        'explicacion': ["‚ö†Ô∏è Datos Colapsados: Se ha usado el promedio total por falta de flujo constante."],
        'df_b': batches
    }, None

    # 2. C√°lculo de la Moda (Pico de la Monta√±a Gamma)
    kde = gaussian_kde(frontera_data)
    x_range = np.linspace(frontera_data.min(), frontera_data.max(), 1000)
    tc_moda_seg = x_range[np.argmax(kde(x_range))]
    
    # 3. C√°lculo de la Mediana
    tc_mediana_seg = frontera_data.median()
    
    # --- MOTOR DE EXPLICACI√ìN ---
    razones = []
    ratio_desvio = tc_moda_seg / tc_obj_seg
    
    if ratio_desvio > 2:
        razones.append(f"‚ö†Ô∏è El TC es {ratio_desvio:.1f}x mayor al objetivo.")
        # Analizar por qu√©
        gaps_grandes = batches[batches['gap'] > 300]['gap'].sum()
        total_time = (df[c_fec].max() - df[c_fec].min()).total_seconds()
        pct_inactividad = (gaps_grandes / total_time) * 100 if total_time > 0 else 0
        
        if pct_inactividad > 40:
            razones.append(f"üîç Causa detectada: Alta inactividad ({pct_inactividad:.1f}% del tiempo son paros > 5 min).")
        
        batching_level = batches['piezas'].mean()
        if batching_level > 5:
            razones.append(f"üîç Causa detectada: Nivel de batching alto ({batching_level:.1f} piezas/seg). El sistema SOAC est√° volcando datos en bloque.")

    return {
        'teorico': tc_moda_seg / 60,
        'real': tc_mediana_seg / 60,
        'modo_seg': tc_moda_seg,
        'explicacion': razones,
        'df_b': batches
    }, None

# --- 3. UI ---
uploaded_file = st.file_uploader("Sube el archivo de Spectrum/SOAC", type=["xls", "xml", "xlsx"])

if uploaded_file:
    with st.spinner("ü§ñ Analizando y auditando registros..."):
        df_raw, _ = load_and_map(uploaded_file)
        
        if df_raw is not None:
            res, err = analyze_with_explanation(df_raw, tc_esperado_seg)
            
            if err:
                st.error(err)
            else:
                st.success("‚úÖ An√°lisis Completado")
                
                # KPIs
                c1, c2, c3 = st.columns(3)
                c1.metric("‚è±Ô∏è TC TE√ìRICO (Moda)", f"{res['teorico']:.2f} min", 
                          help=f"Ritmo m√°s frecuente: {res['modo_seg']:.1f}s")
                c2.metric("‚è±Ô∏è TC REAL (Mediana)", f"{res['real']:.2f} min")
                cap = (h_turno * 60) / res['teorico']
                c3.metric("üì¶ Capacidad Nominal", f"{int(cap)} uds")

                # EXPLICACI√ìN T√âCNICA
                if res['explicacion']:
                    with st.expander("üìù Diagn√≥stico de la IA sobre el tiempo de ciclo", expanded=True):
                        for r in res['explicacion']:
                            st.write(r)
                        st.info("Recomendaci√≥n: Para acercarse a los 110s, el proceso requiere un flujo unitario (One-Piece Flow) en lugar de volcados en lote.")

                # GR√ÅFICA DE DENSIDAD
                st.subheader("üìä Distribuci√≥n de la Firma Temporal")
                fig = px.histogram(res['df_b'][res['df_b']['tc_unitario'] < 600], x="tc_unitario", 
                                 nbins=100, title="Frecuencia de Ritmos Detectados",
                                 color_discrete_sequence=['#2ecc71'])
                fig.add_vline(x=res['modo_seg'], line_dash="dash", line_color="red", 
                             annotation_text=f"Pico Real: {res['modo_seg']:.1f}s")
                st.plotly_chart(fig, use_container_width=True)

        else:
            st.error("Formato de archivo no reconocido o cabeceras faltantes.")

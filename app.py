import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from bs4 import BeautifulSoup
from scipy.stats import gaussian_kde

# --- CONFIGURACIÃ“N PROFESIONAL ---
st.set_page_config(page_title="Celestica Precision Flow AI", layout="wide", page_icon="ğŸ¯")
st.title("ğŸ¯ Celestica IA: Smart-Tracker de Alta PrecisiÃ³n")

with st.sidebar:
    st.header("âš™ï¸ ConfiguraciÃ³n de IngenierÃ­a")
    tc_esperado_seg = st.number_input("TC Objetivo (seg)", value=120)
    h_turno = st.number_input("Horas Turno", value=8.0)
    st.divider()
    st.info("Algoritmo v12.0: Optimizado para distribuciones Gamma y rÃ¡fagas de servidor.")

# --- 1. LECTOR DE ALTA COMPATIBILIDAD ---
def parse_xml_robust(file):
    try:
        content = file.getvalue().decode('latin-1', errors='ignore')
        if "<?xml" not in content and "Workbook" not in content: return None
        soup = BeautifulSoup(content, 'lxml-xml')
        data = [[c.get_text(strip=True) for c in row.find_all(['Cell', 'ss:Cell'])] 
                for row in soup.find_all(['Row', 'ss:Row'])]
        return pd.DataFrame([d for d in data if d])
    except: return None

@st.cache_data(ttl=3600)
def load_and_map(file):
    df = parse_xml_robust(file)
    if df is None or df.empty:
        try:
            file.seek(0)
            df = pd.read_excel(file, header=None)
        except: return None, None
    
    df = df.astype(str)
    # Buscador de cabecera dinÃ¡mico
    header_idx = -1
    for i in range(min(100, len(df))):
        row = " ".join(df.iloc[i]).lower()
        if any(x in row for x in ['date', 'time', 'station', 'productid', 'sn']):
            header_idx = i; break
            
    if header_idx == -1: return None, None
    df.columns = df.iloc[header_idx].str.strip()
    df = df[header_idx + 1:].reset_index(drop=True)

    cols = {
        'Fecha': next((c for c in df.columns if any(x in c.lower() for x in ['date', 'time', 'fecha'])), None),
        'SN': next((c for c in df.columns if any(x in c.lower() for x in ['serial', 'sn', 'unitid'])), None),
        'Product': next((c for c in df.columns if any(x in c.lower() for x in ['product', 'item'])), 'Producto'),
        'Family': next((c for c in df.columns if any(x in c.lower() for x in ['family', 'familia'])), 'Familia')
    }
    return df, cols

# --- 2. CEREBRO DE PRECISIÃ“N ESTADÃSTICA ---
def analyze_precision_cycle(df, cols):
    c_fec = cols['Fecha']
    c_sn = cols['SN']
    
    # A. Limpieza y DeduplicaciÃ³n Estricta
    df[c_fec] = pd.to_datetime(df[c_fec], dayfirst=True, errors='coerce')
    df = df.dropna(subset=[c_fec]).sort_values(c_fec)
    if c_sn:
        df = df.drop_duplicates(subset=[c_sn], keep='first')
    
    # B. CÃ¡lculo de Gaps de Flujo
    # Calculamos el tiempo entre cada registro Ãºnico
    df['Gap_Sec'] = df[c_fec].diff().dt.total_seconds().fillna(0)
    
    # C. Filtrado de "Zona de Flujo Humano"
    # Ignoramos rÃ¡fagas de servidor (< 5s) y paradas de descanso (> 15 min)
    # Esto aÃ­sla los datos donde el operario estÃ¡ trabajando activamente
    flujo_activo = df[(df['Gap_Sec'] >= 10) & (df['Gap_Sec'] <= 900)]['Gap_Sec'].values
    
    if len(flujo_activo) < 10:
        # Fallback: Si no hay flujo, calculamos el rendimiento por ventanas de densidad
        return None

    # D. ESTIMACIÃ“N DE DENSIDAD (KDE) - Encontrando el 1.40 min / 120s
    # Usamos la escala logarÃ­tmica para manejar la cola larga de la distribuciÃ³n Gamma
    log_data = np.log1p(flujo_activo)
    kde = gaussian_kde(log_data)
    x_range = np.linspace(log_data.min(), log_data.max(), 1000)
    tc_teorico_seg = np.expm1(x_range[np.argmax(kde(x_range))])
    
    # El TC Real (Mediana del flujo activo)
    tc_real_seg = np.median(flujo_activo)
    
    return {
        'teo_min': tc_teorico_seg / 60,
        'real_min': tc_real_seg / 60,
        'modo_seg': tc_teorico_seg,
        'muestras': len(flujo_activo),
        'df_plot': flujo_activo
    }

# --- 3. UI Y RESULTADOS ---
uploaded_file = st.file_uploader("Sube el reporte (1.9MB / 15.4MB)", type=["xls", "xml", "xlsx"])

if uploaded_file:
    with st.spinner("ğŸ¤– Aplicando filtros de flujo de precisiÃ³n..."):
        df_raw, cols = load_and_map(uploaded_file)
        
        if df_raw is not None and cols['Fecha']:
            res = analyze_precision_cycle(df_raw, cols)
            
            if res:
                st.success("âœ… AnÃ¡lisis de Flujo Realizado con Ã‰xito")
                
                # KPIs PRINCIPALES (DiseÃ±o Limpio)
                c1, c2, c3 = st.columns(3)
                c1.metric("â±ï¸ TC TEÃ“RICO (Target)", f"{res['teo_min']:.2f} min", 
                          help=f"Ritmo de mÃ¡xima densidad detectado: {res['modo_seg']:.1f}s")
                c2.metric("â±ï¸ TC REAL (Sostenido)", f"{res['real_min']:.2f} min",
                          delta=f"{((res['real_min']/res['teo_min'])-1)*100:.1f}% DesvÃ­o", delta_color="inverse")
                
                capacidad = (h_turno * 60) / res['teo_min']
                c3.metric("ğŸ“¦ Capacidad Nominal", f"{int(capacidad)} uds", help="Capacidad al 100% de eficiencia teÃ³rica.")

                st.divider()

                # --- VISUALIZACIÃ“N DE DISTRIBUCIÃ“N ---
                st.subheader("ğŸ“Š DiagnÃ³stico de la Curva de ProducciÃ³n (Gamma)")
                st.caption("El pico indica el ritmo mÃ¡s estable de la lÃ­nea. La cola hacia la derecha representa las ineficiencias.")
                
                # Histograma de los gaps de flujo activo
                fig = px.histogram(x=res['df_plot'], nbins=100, 
                                 title="Densidad de Tiempos de Ciclo (Datos Filtrados)",
                                 labels={'x': 'Segundos por Pieza'},
                                 color_discrete_sequence=['#2ecc71'])
                
                fig.add_vline(x=res['modo_seg'], line_dash="dash", line_color="red", line_width=4, 
                             annotation_text=f"PICO TEÃ“RICO: {res['modo_seg']:.1f}s")
                st.plotly_chart(fig, use_container_width=True)

                # --- TABLA DE RENDIMIENTO ---
                st.subheader("ğŸ“‹ Resumen por EstaciÃ³n y Producto")
                resumen = df_raw.groupby([cols['Product']]).size().reset_index(name='Unidades')
                resumen['Horas Est. (TeÃ³rico)'] = (resumen['Unidades'] * res['teo_min']) / 60
                st.dataframe(resumen.sort_values('Unidades', ascending=False), use_container_width=True)
                
            else:
                st.error("No se pudo detectar un patrÃ³n de flujo. El archivo podrÃ­a contener solo registros masivos (batch) sin marcas de tiempo individuales.")
        else:
            st.error("Formato de archivo no reconocido o faltan columnas esenciales.")
